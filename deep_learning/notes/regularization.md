# 正则化笔记

在机器学习中,正则化的目的一般是为了让模型减少泛化误差而不是训练误差.也就是能让模型更加泛化,避免过拟合和欠拟合的情况.一般的做法是对参数加一些惩罚和约束,例如给参数加一个正则项,来控制模型的能力.

正则化不论在机器学习还是深度学习中都有重要的地位.它能够让我们的模型更加接近真实数据的生成过程,而不是仅仅去"记住"训练数据的生成过程.

## 参数范数惩罚

许多正则化方法是通过对目标函数$J$添加一个参数范数惩罚$\Omega(\theta)$,限制模型的学习能力.我们把正则化之后的目标函数记为$\tilde{J}$:

$$\tilde{J}(\theta;X,y)=J(\theta;X,y)+\alpha\Omega(\theta)$$

其中$\alpha\in[0,\infty)$权衡参数惩罚项对目标函数的贡献.选择不同的参数范数$\Omega$会偏好不同的解.我们会讨论多种参数范数的选择.

在神经网络中,我们通常只对权重做惩罚而不对偏置做惩罚,因为正则化偏置可能会导致明显的欠拟合.我们使用$w$表示需要正则化的参数,使用$\theta$表示所有的参数.

### $L^2$参数正则化

$L^2$参数范数惩罚也被叫做**权重衰减**.这种正则化策略通过向目标函数添加正则项$\frac{1}{2}||w||^2_2$使权重更加接近原点.$L^2$也被叫做岭回归或Tikhonov正则.

$L^2$正则化为:

$$\tilde{L}(w;X,y)=\frac{\alpha}{2}w^Tw+J(w;X,y)$$

则与之对应的梯度为:

$$\nabla_w\ {\tilde{J}}(w;X,y)=\alpha w+\nabla_w\ J(w;X,y)$$

此时梯度下降执行的更新为:

$$w\leftarrow w-\epsilon(\alpha w+\nabla_w\ J(w;X,y))$$

上述写法可以更改为:

$$w\leftarrow (1-\epsilon\alpha)w-\epsilon\nabla_w\ J(w;X,y)$$

也就是说,在加入正则化之后,在每步执行梯度更新之前,先对权值进行缩放.

上面是正则化对单步更新的影响,下面研究其对于整个过程的影响.我们假设$w^*$是不使用正则化所得到的最优参数.即$w^ *=\arg\min_wJ(w)$.为了简便,我们对目标函数做二次近似(两阶泰勒展开),假设$H$为$J$在$w^ *$处的Hessian矩阵,则近似为:

$$\tilde{J}(\theta)=J(w^*)+\frac{1}{2}(w-w^ *)^TH(w-w^ *)$$

因为$w^*$是最优的,所以$J$关于其一阶导数为0,所以上述近似中没有一阶项.同时,$H$是半正定的.

进一步得到其梯度:

$$\nabla_w\ \tilde{J}(w)=H(w-w^*)$$

因为梯度已经消失,所以上式为0,加上权重衰减的梯度,有:

$$\alpha\tilde{w}+H(w-w^*)=0$$

通过上式可以得出正则化后的最优参数和未正则化的最优参数之间的关系:

$$\tilde{w}=(H+\alpha I)^{-1}Hw^*$$

可以很清楚地看到,当$\alpha$趋向于0,$\tilde{w}$趋向于$w^*$.现在对$H$做特征分解(因为$H$是Hessian矩阵,所以其特征值是$J$关于$w$沿着特征向量的方向导数),$H=Q\Lambda Q^T$.其中$Q$是标准正交基,$\Lambda$是对角矩阵.则有:

$$\tilde{w}=Q(\Lambda+\alpha I)^{-1}\Lambda Q^Tw^*$$

我们看到这里权重衰减的本质就是沿着$H$的特征向量所定义的轴缩放$w^*$.这说明权重衰减会保留权重中那些重要的方向的分量($H$特征值较大,则权重衰减的影响更小,而特征值较大的方向对应于高曲率的方向,即学习效果较好的方向),而对于不重要方向的分量会在训练过程中被衰减掉.

### $L^1$参数正则化

$L^1$正则化非常简单,使用的是$||w||_1$,正则化定义为:

$$\Omega(\theta)=||w||_1=\sum_i|w_i|$$
