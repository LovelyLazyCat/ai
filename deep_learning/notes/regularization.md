# 正则化笔记

在机器学习中,正则化的目的一般是为了让模型减少泛化误差而不是训练误差.也就是能让模型更加泛化,避免过拟合的情况.一般的做法是对参数加一些惩罚和约束,例如给参数加一个正则项,来控制模型的能力.

正则化不论在机器学习还是深度学习中都有重要的地位.它能够让我们的模型更加接近真实数据的生成过程,而不是仅仅去"记住"训练数据的生成过程.

## 参数范数惩罚

许多正则化方法是通过对目标函数$J$添加一个参数范数惩罚$\Omega(\theta)$,限制模型的学习能力.我们把正则化之后的目标函数记为$\tilde{J}$:

$$\tilde{J}(\theta;X,y)=J(\theta;X,y)+\alpha\Omega(\theta)$$

其中$\alpha\in[0,\infty)$权衡参数惩罚项对目标函数的贡献.选择不同的参数范数$\Omega$会偏好不同的解.我们会讨论多种参数范数的选择.

在神经网络中,我们通常只对权重做惩罚而不对偏置做惩罚,因为正则化偏置可能会导致明显的欠拟合.我们使用$w$表示需要正则化的参数,使用$\theta$表示所有的参数.

### $L^2$参数正则化

$L^2$参数范数惩罚也被叫做**权重衰减**.这种正则化策略通过向目标函数添加正则项$\frac{1}{2}||w||^2_2$使权重更加接近原点.$L^2$也被叫做岭回归或Tikhonov正则.

$L^2$正则化为:

$$\tilde{L}(w;X,y)=\frac{\alpha}{2}w^Tw+J(w;X,y)$$

则与之对应的梯度为:

$$\nabla_w\ {\tilde{J}}(w;X,y)=\alpha w+\nabla_w\ J(w;X,y)$$

此时梯度下降执行的更新为:

$$w\leftarrow w-\epsilon(\alpha w+\nabla_w\ J(w;X,y))$$

上述写法可以更改为:

$$w\leftarrow (1-\epsilon\alpha)w-\epsilon\nabla_w\ J(w;X,y)$$

也就是说,在加入正则化之后,在每步执行梯度更新之前,先对权值进行缩放.

上面是正则化对单步更新的影响,下面研究其对于整个过程的影响.我们假设$w^*$是不使用正则化所得到的最优参数.即$w^ *=\arg\min_wJ(w)$.为了简便,我们对目标函数做二次近似(两阶泰勒展开),假设$H$为$J$在$w^ *$处的Hessian矩阵,则近似为:

$$\tilde{J}(\theta)=J(w^*)+\frac{1}{2}(w-w^ *)^TH(w-w^ *)$$

因为$w^*$是最优的,所以$J$关于其一阶导数为0,所以上述近似中没有一阶项.同时,$H$是半正定的.

进一步得到其梯度:

$$\nabla_w\ \tilde{J}(w)=H(w-w^*)$$

因为梯度已经消失,所以上式为0,加上权重衰减的梯度,有:

$$\alpha\tilde{w}+H(w-w^*)=0$$

通过上式可以得出正则化后的最优参数和未正则化的最优参数之间的关系:

$$\tilde{w}=(H+\alpha I)^{-1}Hw^*$$

可以很清楚地看到,当$\alpha$趋向于0,$\tilde{w}$趋向于$w^*$.现在对$H$做特征分解(因为$H$是Hessian矩阵,所以其特征值是$J$关于$w$沿着特征向量的方向导数),$H=Q\Lambda Q^T$.其中$Q$是标准正交基,$\Lambda$是对角矩阵.则有:

$$\tilde{w}=Q(\Lambda+\alpha I)^{-1}\Lambda Q^Tw^*$$

我们看到这里权重衰减的本质就是沿着$H$的特征向量所定义的轴缩放$w^*$.这说明权重衰减会保留权重中那些重要的方向的分量($H$特征值较大,则权重衰减的影响更小,而特征值较大的方向对应于高曲率的方向,即学习效果较好的方向),而对于不重要方向的分量会在训练过程中被衰减掉.

### $L^1$参数正则化

$L^1$正则化非常简单,使用的是$||w||_1$,正则化定义为:

$$\Omega(\theta)=||w||_1=\sum_i|w_i|$$

正则化后的目标函数为:

$$\tilde{J}(w;X,y)=\alpha||w||_1+J(w;X,y)$$

其梯度为:

$$\nabla_w\ \tilde{J}(w;X,y)=\alpha\ \mathbf{sign}(w)+\nabla_w\ J(w;X,y)$$

这里的sign是简单地取$w$各个元素的正负号.

相比于$L^2$正则化,$L^1$正则化会产生更加**稀疏**的解.也就是解中的一些参数为0.而$L^2$正则化产生的并不是稀疏解.

$L^1$正则化导出的这种稀疏性质被广泛用于**特征选择**.特征选择从可用的特征集中选择出有意义的特征.也就是那些为0的特征可以被我们放心地忽略,从而选择出对模型影响较大的特征.

## 作为约束的范数惩罚

上面的范数惩罚实际上可以看做是一种对于权重的约束.因此我们可以把问题转变为构造一个Lagrange函数来最小化带约束的函数.即在原始的目标函数上增加Karush-Kuhn-Tucker乘子和表示约束是否满足的函数的乘积,例如想约束$\Omega(\theta)$(在范数约束中,它是参数的范数)小于某个常数$k$,我们的Lagrange函数为:

$$\mathcal{L}(\theta,\alpha;X,y)=J(\theta;X,y)+\alpha(\Omega(\theta)-k)$$

则我们约束问题的解为:

$$\theta^*=\arg\min\limits_\theta\max_{\alpha,\alpha\ge0}\mathcal{L}(\theta,\alpha;X,y)$$

可以把参数$\alpha$固定为$\alpha^*$,则约束问题只需要考虑$\theta$:

$$\theta^*=\arg\min\limits_\theta J(\theta,\alpha;X,y)+\alpha^ *\Omega(\theta)$$

这样问题就和最小化$\tilde{J}$的问题是完全一样的.因此范数惩罚,或者说权重衰减问题可以看做对权重加一个约束.如果$\Omega$是$L^2$范数,那么权重就被约束在一个"球"中(权重不能偏离这个球),如果$\Omega$是$L^1$范数,则权重被约束在一个区域中.

## 提前终止

如果我们的模型有足够强大的能力,在训练的时候会发现,训练误差一般会一直持续下降,而验证误差在一开始会逐渐降低,随后会再次上升.

**提前终止**要求我们在验证误差没有继续改善时终止训练,即使训练误差还在减小.提前终止是一种非常简单的正则化形式,我们只需要把训练代数Epoch作为超参数调整即可.我们无需对学习模型本身进行太多的调整.因此它非常流行.

提前终止在某些特定条件下(目标函数可以进行二次近似),且参数满足(具体数学推导过程不再列出,详见花书7.8节):

$$(I-\epsilon\Lambda)^\tau=(\Lambda+\alpha I)^{-1}\alpha$$

的情况下,可以看做和$L^2$正则拥有相同的效果.也就是长度为$\tau$的轨迹结束于$L^2$正则化的极小点.而提前终止实现只需要监控验证误差,它比权重衰减更加具有优势.

## 参数绑定和共享

假设现在我们有两个模型$\hat{y}^{(A)}=f(w^{(A)},x)$和$\hat{y}^{(B)}=f(w^{(B)},x)$,它们执行相同的分类任务,仅仅是输入有所不同.这时候我们有充分的理由认为它们的参数应该是足够相似的.

所以,可以增加一个新的范数惩罚$\Omega(w^{(A)},w^{(B)})=||w^{(A)}-w^{(B)}||^2_2$.这里使用$L^2$范数,当然可以选择其余的范数.

通过增加这个惩罚,我们可以让两个模型的参数比较相似,这种方法叫做**参数绑定**.

另外一种约束更加极端,它强制要求两个模型的某些参数是相等的.这叫做**参数共享**.在卷积神经网络中,参数共享的应用比较广,它可以广泛地节省内存资源.例如,一个模型用于区分一只小狗和小猫,另外一个模型用于检测猫的类型,则它们关于猫的一些参数就可以存在一起,这些参数只占用了一份内存.

## 稀疏表示

权重衰减直接对模型参数进行惩罚,另一种策略是惩罚神经网络中的激活单元,这样可以稀疏化激活单元.这种策略间接地对模型参数施加了惩罚.这个过程也叫做**稀疏表示**,表示来源于输入,它是激活单元的输出结果$h$.

那么新的损失函数为:

$$\tilde{J}(\theta;X,y)=J(\theta;X,y)+\alpha\Omega(h)$$

对表示使用$L^1$正则化,即$\Omega(h)=||h||_1$,就可以实现对表示的稀疏.

## Bagging

**Bagging(Bootstrap aggregating)**结合不同的模型来提高模型的泛化程度,它训练多个不同的模型,然后让所有模型表决测试样例的输出.这样的方法在机器学习中用得比较多,叫做**模型平均**.采用这种策略的技术叫做**集成方法**.

假设有$k$个回归模型,集成方法中每个模型在每个例子上的误差是$\epsilon_i$,这个误差服从均值方差为$\mathbb{E} [ \epsilon^2_i]=v$且协方差为$\mathbb{E} [ \epsilon_i\epsilon_j]=c$的多维正态分布.

则集成预测器平方误差的均值为:

$$\mathbb{E} [ (\frac{1}{k}\sum_i\epsilon_i)^2]=\frac{1}{k^2}\mathbb{E} [ \sum_i(\epsilon^2_i+\sum_{i\ne j}\epsilon_i\epsilon_j)]=\frac{1}{k}v+\frac{k-1}{k}c$$

在误差完全相关的情况下($c=v$),模型平均没有任何帮助.在误差完全不相关即$c=0$时,集成平方误差的期望为$\frac{1}{k}v$.这意味集成平方误差的期望会随着集成规模的增大而减小.

也就是说,集成至少表现得与它的任何成员一样好,并且如果成员之间的误差是独立的,集成表现得将会更好.

构建Bagging的方法有很多,为了让成员之间的误差独立,我们可以让不同的模型侧重于不同的数据,这样单独一个模型产生的结果是不可靠的,但是进行集成平均后就能产生相对可靠的模型.

## Dropout

在神经网络中使用Bagging似乎并不合适.因为每个神经网络模型都是无比庞大的.训练和评估这样的网络需要花费大量的时间和内存,因此直接训练多个神经网络似乎并不好.

这里就诞生了**Dropout**.这是集成大量深层神经网络的实用Bagging方法.Dropout训练由很多子网络组成,这些子网络是从基本网络中删除非输出单元构建的.对于包含Dropout的神经网络,每个层都有一个超参数,叫做采样率.表示在一次训练的时候保留这个单元的概率.没有保留的单元将不会参与本次前馈和反向传播.

Dropout和Bagging不一样之处在于,在Bagging的时候,所有模型都是独立的.而在Dropout的时候模型之间的参数是共享的.

注意Dropout是一个正则化技术,它减少了模型的有效容量.为了抵消这种影响,我们需要增大模型的规模.并且Dropout在极小的训练样本可用时不会这么有效.但是在模型足够庞大且训练数据充足的情况下,Dropout一般都能让验证误差小很多.

关于如何计算Dropout输出的分布,已经Dropout的更多技术细节,参见花书7.12节.
