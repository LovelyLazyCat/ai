{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 使用TensorFlow解决iris问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eager Execution可以使TensorFlow立即评估各项操作，并返回具体的值，不会创建稍后执行的计算图。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lazycat/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/Users/lazycat/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version: 1.10.1\n",
      "Eager execution: True\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.eager as tfe\n",
    "\n",
    "tf.enable_eager_execution()\n",
    "\n",
    "print(\"Tensorflow version: {}\".format(tf.VERSION))\n",
    "print(\"Eager execution: {}\".format(tf.executing_eagerly()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下载数据集，并储存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local copy of the dataset file: /Users/lazycat/.keras/datasets/iris_training.csv\n"
     ]
    }
   ],
   "source": [
    "train_data_url = \"http://download.tensorflow.org/data/iris_training.csv\"\n",
    "train_data_fp = tf.keras.utils.get_file(fname=os.path.basename(train_data_url), origin=train_data_url)\n",
    "\n",
    "print(\"Local copy of the dataset file: {}\".format(train_data_fp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_csv(line):\n",
    "    defaults = [[0.], [0.], [0.], [0.], [0]]\n",
    "    parsed_line = tf.decode_csv(line, defaults)\n",
    "    # 提取前4个特征值\n",
    "    features = tf.reshape(parsed_line[:-1], shape=(4,))\n",
    "    # 提取最后一个标签值\n",
    "    label = tf.reshape(parsed_line[-1], shape=())\n",
    "    return features, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example features: tf.Tensor([5.  2.3 3.3 1. ], shape=(4,), dtype=float32)\n",
      "example label: tf.Tensor(1, shape=(), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "train_data = tf.data.TextLineDataset(train_data_fp)\n",
    "\n",
    "# 跳过第一行Hdeader\n",
    "train_data = train_data.skip(1)\n",
    "\n",
    "# 对每一行进行处理\n",
    "train_data = train_data.map(parse_csv)\n",
    "\n",
    "# 随机化数据\n",
    "train_data = train_data.shuffle(buffer_size=1000)\n",
    "\n",
    "train_data = train_data.batch(32)\n",
    "\n",
    "features, label = iter(train_data).next()\n",
    "print(\"example features:\", features[0])\n",
    "print(\"example label:\", label[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 使用神经网络来解决分类问题\n",
    "\n",
    "使用密集型神经网络，隐藏层是密集层。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义模型，注意第一个密集层需要指定输入规模\n",
    "# 这里有4个特征值，所以输入规模是4\n",
    "# 输出密集层的参数是3，因为有3种花的种类\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, activation='relu', input_shape=(4,)),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(3)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练模型\n",
    "\n",
    "在训练模型之前，需要计算模型的损失。这样可以衡量模型的预测结果和预期标签有多大偏差。通过这个偏差可以调整模型。\n",
    "\n",
    "同时还要定义梯度，梯度用于在训练的时候优化模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(model, x, y):\n",
    "    y_ = model(x)\n",
    "    return tf.losses.sparse_softmax_cross_entropy(labels=y, logits=y_)\n",
    "\n",
    "\n",
    "def grad(model, inputs, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        loss_val = loss(model, inputs, targets)\n",
    "    return tape.gradient(loss_val, model.variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 随机梯度"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
